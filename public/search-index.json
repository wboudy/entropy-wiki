[
  {
    "id": "beads",
    "title": "README",
    "content": "Beads System Manual Version: 1.0 Purpose: Technical reference for AI agents managing persistent memory and multi-session work  Overview Beads is a git-backed issue tracking system designed for AI agents to maintain context across conversation sessions, manage dependencies, and coordinate complex multi-session work. This manual serves as training data for understanding beads workflows and memory management.  Core Concepts What is a Bead? - A persistent work item tracked across sessions - Stored in  directory as structured data - Version-controlled via git for history and collaboration - Supports dependencies, blocking relationships, and priority When to Use Beads vs TodoWrite: - Use Beads for:   - Multi-session work that spans conversations   - Tasks with blocking dependencies   - Strategic work requiring context recovery after compaction   - Discovered work that needs tracking beyond current session - Use TodoWrite for:   - Simple single-session execution   - Immediate task breakdown w",
    "url": "/beads",
    "category": "beads"
  },
  {
    "id": "beads/cli-reference",
    "title": "cli-reference",
    "content": "CLI Reference: bd Command Complete reference for the  command-line interface.  Command Structure  Global Options Available for all commands: -  - Show help for command -  - Show beads version ---  Core Commands   Initialize beads in the current project. What it does: - Creates  directory structure - Initializes config and index files - Sets up git integration - Configures hooks When to use: - First-time setup in a new repository - After cloning a repo without beads ---   Create a new issue. Options: -  - Issue title (required) -  - Issue type: , , ,  (default: ) -  - Priority: 0-4 or P0-P4 (0=critical, 4=backlog, default: 2) -  - Assign to user -  - Issue description -  - Associate with epic Examples: Parallel Creation: For efficiency when creating multiple issues, use parallel subagents. ---   List issues with optional filters. Options: -  - Filter by status: , , ,  -  - Filter by type: , , ,  -  - Filter by priority: 0-4 or P0-P4 -  - Filter by assignee -  - Show issues in epic Examp",
    "url": "/beads/cli-reference",
    "category": "beads"
  },
  {
    "id": "beads/dependencies",
    "title": "dependencies",
    "content": "Dependency Resolution  Overview Beads uses a dependency graph to model blocking relationships between issues. Dependencies enable: - Explicit ordering constraints (\"A must complete before B\") - Automatic priority surfacing via PageRank - Blocking/unblocking cascade detection - Strategic work sequencing  Dependency Model  Terminology Dependency Relationship: Graph Representation: - Nodes: Individual issues - Edges: Dependency relationships (directed) - Direction: Edge points from dependent to dependency   -  means \"A depends on B\" (B blocks A)  Dependency Commands Add Dependency: Remove Dependency: View Dependencies:  PageRank-Based Priority  Why PageRank? Traditional priority systems (P0-P4) are static and don't account for strategic impact. PageRank dynamically calculates importance based on how many issues a given issue unblocks. Core Insight: Issues that unblock many other issues should be prioritized, even if their nominal priority is lower.  How It Works 1. Graph Construction:    ",
    "url": "/beads/dependencies",
    "category": "beads"
  },
  {
    "id": "beads/lifecycle",
    "title": "lifecycle",
    "content": "Bead Lifecycle  State Model A bead progresses through discrete states that represent its position in the work pipeline. Understanding these states is critical for effective memory management and work coordination.  States  1. Open (Initial State) Meaning: Issue has been created but work has not started. Characteristics: - Newly created issues start here - Available for assignment - May have dependencies (blockers) - Visible in  Valid Transitions: - →  (work begins) - →  (cancelled or determined unnecessary) Commands:  2. In Progress (Active Work) Meaning: An agent or human is actively working on this issue. Characteristics: - Indicates current focus area - Should have assignee - One agent should work on one issue at a time - Visible in  Valid Transitions: - →  (dependency or external blocker discovered) - →  (work completed) - →  (work paused/reassigned) Commands:  3. Blocked (Waiting) Meaning: Work cannot proceed due to dependencies or external factors. Characteristics: - Has explicit",
    "url": "/beads/lifecycle",
    "category": "beads"
  },
  {
    "id": "beads/workflows",
    "title": "workflows",
    "content": "Common Workflows Practical patterns for using beads effectively in different scenarios.  Daily Development Flow  Morning: Finding Work  During Work: Discovering Dependencies  End of Day: Wrapping Up ---  Feature Development Workflow  Phase 1: Planning  Phase 2: Execution  Phase 3: Completion ---  Bug Fix Workflow  Rapid Fix (Single Session)  Complex Bug (Multi-Session) ---  Refactoring Workflow  Incremental Refactor ---  Blocked Work Recovery  Scenario: External Blocker ---  Collaboration Workflow  Taking Over Work  Sync and Conflict Resolution ---  Context Recovery Workflow  After Conversation Compaction  After Long Break ---  Strategic Planning Workflow  Epic with Parallel Tracks ---  Maintenance Workflow  Weekly Cleanup  Monthly Audit ---  Anti-Patterns to Avoid  1. Too Many In-Progress Issues Bad: Good:  2. Ignoring Dependencies Bad: Good:  3. Manual Priority Override Bad: Good:  4. Creating Without Planning Bad: Good:  5. Not Using Comments Bad: Good: ---  Summary: Key Principles ",
    "url": "/beads/workflows",
    "category": "beads"
  },
  {
    "id": "content-mapping",
    "title": "Content Mapping",
    "content": "Content Mapping: docs/ to wiki/ This document maps all files in  to their target destinations in .  Summary - Total files in docs/: 35 - Files to migrate: 35 - Target sections: 7 (context, orchestration, plugins, skills-bank, tooling-mcp, beads, gastown)  Mapping by Source Directory  /docs/agent-knowledge-base/ | Source | Target | Status | |--------|--------|--------| | INDEX.md | wiki/home.md (merged) | Overlap | | claude-code-essentials.md | wiki/getting-started.md | Novel |  /docs/agent-knowledge-base/context/ | Source | Target | Status | |--------|--------|--------| | agentsmd-spec.md | wiki/context/agents-md-spec.md | Novel | | anthropic-context-engineering.md | wiki/context/context-engineering.md | Novel | | github-par.md | wiki/context/parallel-agents.md | Novel | | google-adk.md | wiki/context/google-adk.md | Novel | | humanlayer-claude-md.md | wiki/context/claude-md-patterns.md | Novel |  /docs/agent-knowledge-base/coordination/ | Source | Target | Status | |--------|--------|",
    "url": "/content-mapping",
    "category": "content-mapping"
  },
  {
    "id": "context",
    "title": "Context",
    "content": "Context Documentation for managing context windows and optimizing information flow in AI-assisted development.  Topics  Context Engineering - Context Engineering - Managing token composition during inference - CLAUDE.md Patterns - Best practices for writing effective CLAUDE.md files - AGENTS.md Specification - Vendor-neutral format for guiding AI agents  Multi-Agent Architecture - Google ADK Architecture - Core concepts from Google's Agent Development Kit - Parallel Worktree Management - Par CLI for concurrent development workflows  Key Concepts  Context Rot LLMs experience performance degradation as context length increases. The more tokens in the context window, the harder it becomes for the model to accurately recall and utilize information.  Context Compaction Summarizing conversations nearing capacity limits to preserve critical decisions while discarding redundant outputs.  Progressive Disclosure Loading files and information only when needed, rather than front-loading everything",
    "url": "/context",
    "category": "context"
  },
  {
    "id": "context/agents-md-spec",
    "title": "AGENTS.md Specification",
    "content": "AGENTS.md Specification Summary  Core Definition AGENTS.md is a vendor-neutral markdown format designed to guide AI coding agents. As stated on the official site: \"A simple, open format for guiding coding agents, used by over 60k open-source projects.\"  Schema and Structure Rather than enforcing a rigid schema, AGENTS.md intentionally remains flexible. The specification explicitly states: \"AGENTS.md is just standard Markdown. Use any headings you like; the agent simply parses the text you provide.\" Common sections include: - Project overview - Build and test commands - Code style guidelines - Testing instructions - Security considerations - PR/commit message guidelines  Agent Personas and Boundaries The format doesn't define specific agent personas but rather creates \"a dedicated, predictable place to provide the context and instructions\" for any AI coding agent to operate effectively. Key boundary principle: \"The closest AGENTS.md to the edited file wins; explicit user chat prompts ov",
    "url": "/context/agents-md-spec",
    "category": "context"
  },
  {
    "id": "context/claude-md-patterns",
    "title": "CLAUDE.md Patterns",
    "content": "CLAUDE.md Specification Summary  Recommended Length CLAUDE.md files should be under 300 lines, with shorter being preferable. HumanLayer's own root file is less than 60 lines.  What to Include The file should cover three essential areas: 1. WHAT - Technical stack and project structure. \"Give Claude a map of the codebase,\" particularly important for monorepos where you clarify apps, shared packages, and their purposes. 2. WHY - Project purpose and the function of different components so Claude understands the system's intent. 3. HOW - Practical workflow information: build tools (e.g.,  vs ), test execution, verification methods, and compilation steps needed for meaningful work.  What to Avoid The article explicitly recommends against: - Code style guidelines - \"Never send an LLM to do a linter's job.\" Use deterministic linters instead. - Excessive instructions - Frontier LLMs can reliably follow \"~150-200 instructions.\" Since Claude Code's system prompt already contains ~50 instructions",
    "url": "/context/claude-md-patterns",
    "category": "context"
  },
  {
    "id": "context/context-engineering",
    "title": "Context Engineering",
    "content": "Context Engineering for AI Agents  Context Engineering vs. Prompt Engineering Prompt engineering focuses on crafting effective LLM instructions, particularly system prompts. Context engineering represents the broader evolution - managing the entire token composition during inference, including system instructions, tools, external data, and message history across multiple turns. As Anthropic explains: \"context engineering is iterative and the curation phase happens each time we decide what to pass to the model.\"  Context Rot Phenomenon LLMs experience performance degradation as context length increases. Research shows that \"as the number of tokens in the context window increases, the model's ability to accurately recall information from that context decreases.\" This stems from transformer architecture's n-squared pairwise token relationships. Models trained on shorter sequences have fewer specialized parameters for long-range dependencies, creating a performance gradient rather than a h",
    "url": "/context/context-engineering",
    "category": "context"
  },
  {
    "id": "context/google-adk",
    "title": "Google ADK Architecture",
    "content": "Google ADK: Core Architectural Concepts  1. Compiled View Concept Google's ADK treats context as a derived representation rather than mutable storage. The framework separates concerns into layers: - Sources: Sessions, memory, and artifacts contain full structured state - Compiler pipeline: Flows and processors transform that state through ordered passes - Output: Working context is the ephemeral projection sent to the LLM As the article states: \"Context is a compiled view over a richer stateful system.\" This shift reframes context management from prompt engineering into systems architecture, where you ask questions about intermediate representations, compaction points, and transformation observability.  2. Handle Pattern for Artifacts Rather than embedding large data (5MB CSVs, PDFs, JSON responses) directly in prompts, ADK uses indirect references: - Large objects live in an  as named, versioned resources - Agents see lightweight summaries by default - The  allows agents to fetch full",
    "url": "/context/google-adk",
    "category": "context"
  },
  {
    "id": "context/parallel-agents",
    "title": "Parallel Worktree Management",
    "content": "Par: Parallel Worktree and Session Manager par is a CLI tool that streamlines concurrent development workflows by combining Git worktrees with tmux session management. It enables developers - particularly those working with AI coding assistants - to manage multiple isolated development environments globally.  Core Functionality The tool creates isolated workspaces where each session gets its own directory, Git branch, and tmux session. As the documentation states, it's designed to solve a fundamental problem: \"traditional Git branch switching is not ideal for handling multiple concurrent workstreams on the same repository.\"  Key Capabilities - Global session management: Create, list, and access development contexts from anywhere on your system - Multi-repository workspaces: Coordinate changes across multiple repositories with synchronized branch naming - Remote command execution: Send commands to specific sessions or broadcast to all contexts simultaneously - IDE integration: Auto-gene",
    "url": "/context/parallel-agents",
    "category": "context"
  },
  {
    "id": "gastown",
    "title": "README",
    "content": "Gastown Documentation Multi-agent orchestration system for Claude Code with persistent work tracking.  Overview Gastown is a workspace manager that coordinates multiple AI agents working on different tasks. Instead of losing context when agents restart, Gastown persists work state in git-backed hooks, enabling reliable multi-agent workflows. This directory contains comprehensive documentation for implementing and operating Gastown rigs.  Documentation  GUPP - Gastown Unified Propulsion Protocol ⭐ The Industrial Constitution of a Gastown Rig Comprehensive guide covering: - Philosophy of Momentum - Core principles for continuous propulsion - Rig Hierarchy - Roles from Human Overseer to Polecats - Coordination Patterns - Sequential, parallel, and escalation workflows - Troubleshooting - Handling \"Ralph Wiggum States\" (degraded agents) - Metrics & Health - KPIs and monitoring procedures Essential reading for: - Human operators setting up or managing Gastown rigs - AI agents (Mayor, Polecat",
    "url": "/gastown",
    "category": "gastown"
  },
  {
    "id": "gastown/gupp",
    "title": "gupp",
    "content": "GUPP: The Gastown Unified Propulsion Protocol The Industrial Constitution of a Gastown Rig Version 1.0 | Philosophy of Momentum for Multi-Agent Coordination ---  Executive Summary GUPP (Gastown Unified Propulsion Protocol) is the operational philosophy and structural framework that governs multi-agent coordination in Gastown rigs. It embodies a philosophy of momentum: systems should always be moving forward, agents should never be idle when work exists, and blockers must be resolved through systematic escalation and delegation. This document serves as the industrial constitution for Gastown operations, defining: - The Rig Hierarchy (roles and responsibilities) - The philosophy of continuous propulsion - Multi-agent coordination patterns - Troubleshooting procedures for degraded states Target Audience: Human operators, AI agents (Mayor, Polecats), and system architects implementing Gastown workflows. ---  Part I: Philosophy of Momentum  Core Principle Momentum is the default state. Idle",
    "url": "/gastown/gupp",
    "category": "gastown"
  },
  {
    "id": "gastown/monitor",
    "title": "monitor",
    "content": "Rig Health Manual: Gauges and Dials Monitoring and Diagnostics for Gastown Rigs Version 1.0 | The Operator's Guide to Rig Telemetry ---  Overview A healthy Gastown rig is like a well-tuned engine: you can feel the rhythm of progress. Issues flow in, agents consume them, work gets completed, and the ledger drains. When the rig stalls or stutters, the gauges tell you why. This manual explains how to monitor your rig's health using the Beads Viewer (bv) and command-line tools. You'll learn to interpret the key metrics that indicate rig vitality: - PageRank - Task importance and unblocking priority - Critical Paths - Bottlenecks preventing progress - Cycle Detection - Logic loops causing infinite dependencies - Pulse - The rhythm indicating whether work is flowing or stalled Target Audience: Human Overseers, Mayors (AI coordinators), and system operators monitoring Gastown rigs. ---  Part I: The Beads Viewer (bv)  What is bv? The Beads Viewer is a terminal-based UI (TUI) for visualizing an",
    "url": "/gastown/monitor",
    "category": "gastown"
  },
  {
    "id": "home",
    "title": "Entropy Wiki",
    "content": "Entropy Wiki Welcome to the Entropy Wiki - a cyber-utilitarian knowledge base for AI-assisted development.  Sections - Beads - Git-backed issue tracking with dependencies and persistent memory - Gastown - Agent orchestration and multi-agent workflows - Orchestration - Task coordination and execution patterns - Plugins - Claude Code plugin development - Prompt Bank - Reusable prompt templates and patterns - Skills Bank - Skill definitions for Claude Code - Tooling MCP - Model Context Protocol server development  Getting Started Browse the sections above to explore the documentation, or use the search bar to find specific topics.",
    "url": "/home",
    "category": "home"
  },
  {
    "id": "lab",
    "title": "Lab",
    "content": "Lab Experimental documentation and features that are still being developed or tested.  Purpose The Lab section contains: - Work-in-progress documentation - Experimental patterns and approaches - Beta features not yet ready for production - Research notes and explorations  Disclaimer Content in this section may be incomplete, unstable, or subject to significant changes.",
    "url": "/lab",
    "category": "lab"
  },
  {
    "id": "orchestration",
    "title": "Orchestration",
    "content": "Orchestration Multi-agent coordination patterns and handoff protocols.  What is Orchestration? Orchestration defines how multiple AI agents work together to solve complex problems. It covers task distribution, state management, and agent-to-agent communication.  Core Concepts Key orchestration patterns include: - Sequential workflows (agent chains) - Parallel execution (concurrent tasks) - Hierarchical coordination (supervisor/worker) - Event-driven handoffs  Ralph Loops (Autonomous Execution) Ralph loops enable autonomous AI development by iterating until tasks are complete: - Ralph Technique - Core concepts and economic model - Ralph Plugin - Claude Code plugin implementation with Stop Hook - Ralph Enterprise - Production-ready implementation with safety guardrails - RepoMirror Experiment - Headless loop analysis for code porting  Multi-Agent Workflows - Claude Code Multi-Agent Workflow - Coordination patterns  Key Patterns  Stop Hook Architecture Intercepts exit attempts to force ve",
    "url": "/orchestration",
    "category": "orchestration"
  },
  {
    "id": "orchestration/claude-code-multi-agent-workflow",
    "title": "claude-code-multi-agent-workflow",
    "content": "Beads + Claude Code: Multi-Agent Workflow Architecture > VER: 1.0.0 > STATUS: Production > LASTUPDATED: 2026-01-08  Question How should we coordinate terminal (bd CLI) and Claude Code when working through epics? One agent per epic, or multiple agents per epic? ---  Answer: Multiple Agents Per Epic (Dependency-Driven Parallelism) Beads is explicitly designed for multi-session AI agent workflows where: - Multiple Claude Code agents work in parallel on different tasks within the same epic - Terminal serves as coordination point for planning and monitoring - Dependencies define execution order, not manual sequencing - Context survives across sessions via git-backed persistence ---  Core Design Philosophy > \"Beads is a git-backed issue tracking system designed for AI agents to maintain context across conversation sessions, manage dependencies, and coordinate complex multi-session work.\" > > —   Key Principle: Persistence Over Optimization - When in doubt, track it in beads - Conversations a",
    "url": "/orchestration/claude-code-multi-agent-workflow",
    "category": "orchestration"
  },
  {
    "id": "orchestration/ralph-enterprise",
    "title": "Ralph Enterprise Implementation",
    "content": "Ralph for Claude Code: Enterprise Implementation  Overview Ralph is a bash-based automation framework enabling continuous autonomous development cycles with Claude Code. It implements Geoffrey Huntley's technique to execute iterative improvements while maintaining safety guardrails.  Core Safety Architecture  Circuit Breaker Pattern The system monitors three failure indicators: \"3 loops with no progress, 5 loops with repeated errors, or output declining >70%.\" When triggered, the circuit opens automatically to prevent runaway execution.  Rate Limiting Ralph enforces hourly API call quotas (configurable, default 100 calls/hour) with countdown timers. It detects Claude's 5-hour usage ceiling and prompts for wait-or-exit decisions rather than entering retry loops.  Stagnation Detection The framework tracks consecutive test-focused iterations (threshold: 3 loops) and repetitive \"done\" signals (threshold: 2 occurrences). Multi-line error matching distinguishes genuine failures from false po",
    "url": "/orchestration/ralph-enterprise",
    "category": "orchestration"
  },
  {
    "id": "orchestration/ralph-plugin",
    "title": "Ralph Wiggum Plugin",
    "content": "Ralph Wiggum Plugin Summary  Overview The Ralph Wiggum plugin implements an iterative AI development loop technique in Claude Code. Named after the persistent Simpsons character, it enables autonomous, self-referential improvement cycles where Claude refines its work iteratively until completion.  Core Architecture: Stop Hook Key Mechanism: A Stop Hook () intercepts Claude's exit attempts and creates a self-referential feedback loop: Why it works: The prompt never changes, but previous work persists in files. Each iteration, Claude sees modified files and git history, enabling autonomous self-improvement by reading its own past work.  Commands  /ralph-loop Options: -  - Stop after N iterations (default: unlimited) -  - Phrase that signals completion (exact string matching)  /cancel-ralph Cancels the active loop immediately.  Verification and Forced Iteration Self-Correction Built-in: - Claude reads test failures, lint errors, and file states - Automatically fixes bugs without re-prompt",
    "url": "/orchestration/ralph-plugin",
    "category": "orchestration"
  },
  {
    "id": "orchestration/ralph-technique",
    "title": "Ralph Technique",
    "content": "The Ralph Technique: Core Concepts and Economic Model  Core Primitive Ralph is fundamentally a simple bash loop that automates code generation: According to the technique, \"Ralph is a technique\" that operates by continuously feeding prompts to an LLM without tool-call limitations, iterating until objectives are met.  Key Characteristics Deterministic Defects: The technique is \"deterministically bad in an undeterministic world.\" This paradox means Ralph's failures are predictable and addressable through prompt refinement rather than tool selection. Skill-Based Operation: Ralph requires iterative tuning - like adjusting an instrument. When Ralph produces errors, the operator modifies prompts (analogous to adding guidance signs) rather than blaming the underlying tool.  Economic Validation The most striking data point: an engineer reportedly delivered a $50,000 contract project for approximately $297 in tool costs. This represents roughly 167x cost reduction, though this doesn't detail ti",
    "url": "/orchestration/ralph-technique",
    "category": "orchestration"
  },
  {
    "id": "orchestration/repo-mirror",
    "title": "RepoMirror Experiment",
    "content": "RepoMirror Experiment: Headless Loop Analysis  Core Methodology The experiment ran Claude Code in an infinite loop via CLI: This approach was inspired by a technique promoted by Geoff Huntley for continuous agent execution.  Empirical Results Scope: 6 ported codebases across ~29 hours of continuous operation - Commits Generated: Approximately 1,100 commits total across all projects - Infrastructure Cost: ~$800 for inference expenses - Runtime Cost: ~$10.50/hour per Sonnet agent running overnight  Ported Projects 1. better-use (Browser Use: Python to TypeScript) - \"almost fully functional\" 2. ai-sdk-python (Vercel AI SDK: TypeScript to Python) 3. open-dedalus (spec-to-code generation from documentation) 4. Plus 3 additional experimental ports  Configuration and Prompts  Minimal Prompt Principle The most effective prompts were simplest. One team member expanded instructions to 1,500 words with Claude's help - the agent immediately \"got slower and dumber.\" Reverting to ~103 words restored",
    "url": "/orchestration/repo-mirror",
    "category": "orchestration"
  },
  {
    "id": "plugins",
    "title": "README",
    "content": "Plugins Claude Code plugins extend the development environment with specialized capabilities for testing, iteration, design, and workflow automation.  What are Plugins? Plugins are packaged extensions that provide: - New skills - Commands that orchestrate complex workflows - MCP servers - Integration with external tools and services - Development patterns - Proven methodologies for AI-assisted development  Installed Plugins This wiki documents the following plugins currently installed:  Playwright Browser automation for visual testing, functional validation, and layout debugging. Enables systematic frontend testing through MCP integration. Learn more →  Ralph Loop Iterative development methodology based on continuous AI loops. Implements the \"Ralph Wiggum\" technique for self-correcting, autonomous task completion. Learn more →  Frontend Design Production-grade interface creation with bold aesthetic direction. Generates distinctive, polished frontend code that avoids generic AI patterns",
    "url": "/plugins",
    "category": "plugins"
  },
  {
    "id": "plugins/frontend-design",
    "title": "frontend-design",
    "content": "Frontend Design Plugin Production-grade interface creation with bold aesthetic direction that avoids generic AI patterns.  Overview The Frontend Design plugin guides creation of distinctive, memorable user interfaces with exceptional attention to aesthetic details and creative choices. It produces real working code (HTML/CSS/JS, React, Vue, etc.) that is: - Visually striking - Memorable and distinctive - Production-grade - Functional and performant - Cohesive - Clear aesthetic point-of-view - Refined - Meticulously detailed  Core Philosophy Avoid \"AI slop\" - Generic aesthetics that scream \"made by AI\": - ❌ Overused fonts (Inter, Roboto, Arial, system fonts) - ❌ Cliched colors (purple gradients on white backgrounds) - ❌ Predictable layouts and component patterns - ❌ Cookie-cutter design lacking context-specific character Embrace bold direction - Commit to a clear conceptual vision: - ✅ Distinctive font pairings - ✅ Cohesive color systems with personality - ✅ Unexpected layouts and compo",
    "url": "/plugins/frontend-design",
    "category": "plugins"
  },
  {
    "id": "plugins/github",
    "title": "github",
    "content": "GitHub CLI Integration Native GitHub operations through the  command for pull requests, issues, code review, and repository management.  Overview GitHub CLI () integration enables Claude Code to interact directly with GitHub repositories through the Bash tool. This provides: - Pull request creation - Create PRs with comprehensive descriptions - Issue management - View, create, and update issues - Code review - Comment on PRs, view diffs, check status - Repository operations - Clone, fork, view details - Release management - Create releases, view tags - GitHub Actions - View workflow runs, check CI status  Installation  1. Install GitHub CLI macOS: Linux: Windows:  2. Authenticate Follow the prompts to authenticate via browser or token.  3. Verify Installation  Core Commands  Pull Requests  Create PR  View PRs  PR Comments  Issues  Create Issue  Manage Issues  Repository  Clone & Fork  Releases  Workflows  View CI Status  Integration with Git Workflow The GitHub CLI enhances the git-wor",
    "url": "/plugins/github",
    "category": "plugins"
  },
  {
    "id": "plugins/playwright",
    "title": "playwright",
    "content": "Playwright Plugin Browser automation for visual testing, functional validation, and layout debugging via Model Context Protocol (MCP) integration.  Overview The Playwright plugin provides a complete browser automation toolkit through MCP, enabling: - Visual regression testing - Screenshot comparisons before/after changes - Functional validation - Verify user interactions and flows - Layout debugging - Inspect CSS, DOM structure, and rendering issues - Responsive testing - Test across different viewport sizes - Accessibility checks - Validate ARIA attributes and semantics  Installation & Setup  1. Configure MCP Server Add to  in project root:  2. Restart Claude Code The MCP server loads on startup. Restart to activate Playwright tools.  3. Verify Installation Check that Playwright tools are available: -  - Navigate to URL -  - Capture accessibility snapshot -  - Take screenshots -  - Click elements -  - Run JavaScript in page context  Available Tools  Navigation -  - Load a page -  - Go",
    "url": "/plugins/playwright",
    "category": "plugins"
  },
  {
    "id": "plugins/ralph-loop",
    "title": "ralph-loop",
    "content": "Ralph Loop Plugin Iterative development methodology based on continuous AI loops for self-correcting, autonomous task completion.  Overview Ralph Loop implements the \"Ralph Wiggum\" technique - a development pattern where Claude repeatedly receives the same prompt while seeing its own previous work, enabling iterative refinement until task completion. Core principle: The AI doesn't need its output fed back as input. It sees its own work in the files and git history, creating a self-referential improvement loop.  The Ralph Wiggum Technique Named after the Simpsons character, this technique embraces being \"deterministically bad in an undeterministic world\" - failures are predictable and can be systematically improved through prompt tuning.  Basic Loop Structure  How It Works 1. Same prompt, every iteration    - Claude receives identical instructions each time    - No modification between loops 2. Self-referential context    - Claude sees its previous work in files    - Reviews git history",
    "url": "/plugins/ralph-loop",
    "category": "plugins"
  },
  {
    "id": "prompt-bank",
    "title": "README",
    "content": "Prompt Bank High-performance, battle-tested prompts for AI agents and LLMs.  What is Prompt Bank? Prompt Bank is a curated collection of effective prompts organized by use case. Each prompt is optimized for clarity, specificity, and reliable output.  Categories Prompts are categorized by: - Task type (generation, analysis, refactoring, etc.) - Domain (code, documentation, data processing) - Complexity level  Usage Each prompt includes: - Clear objective statement - Input format requirements - Expected output structure - Example usage Browse the collection to find prompts that fit your workflow, or use them as templates for custom variations.",
    "url": "/prompt-bank",
    "category": "prompt-bank"
  },
  {
    "id": "prompt-bank/the-refiner",
    "title": "the-refiner",
    "content": "THEREFINER || VER: 1.0.2 > [!NOTE] > Golden prompt for turning rough intent into high-density Gastown-style instructions.  Prompt > [!TIP] > Pair with a domain preface to enforce tone, constraints, and stack context. > [!CAUTION] > Do not leak hidden chain-of-thought. Summaries only.",
    "url": "/prompt-bank/the-refiner",
    "category": "prompt-bank"
  },
  {
    "id": "skills-bank",
    "title": "Skills Bank",
    "content": "Skills Bank A collection of reusable AI agent capabilities and skill definitions.  What is Skills Bank? Skills Bank provides modular, plug-and-play capabilities for AI agents. Each skill is a self-contained unit that can be deployed, tested, and reused across different contexts.  Documentation  Claude Code Skills - Skills Overview - Creating and managing Agent Skills in Claude Code - Best Practices - Writing effective Skills that Claude can discover and use - Template Skill - Starter template for creating new skills  Key Concepts  What is a Skill? A Skill is a markdown file that teaches Claude how to do something specific. Skills are model-invoked - Claude automatically applies relevant Skills when your request matches their description.  Where Skills Live | Location | Path | Applies to | |----------|------|------------| | Personal |  | You, across all projects | | Project |  | Anyone working in this repository | | Plugin | Bundled with plugins | Anyone with the plugin installed |  Ski",
    "url": "/skills-bank",
    "category": "skills-bank"
  },
  {
    "id": "skills-bank/best-practices",
    "title": "Skill Best Practices",
    "content": "Skill Authoring Best Practices Learn how to write effective Skills that Claude can discover and use successfully.  Core Principles  Concise is Key The context window is a public good. Your Skill shares the context window with: - The system prompt - Conversation history - Other Skills' metadata - Your actual request Default assumption: Claude is already very smart. Only add context Claude doesn't already have. Challenge each piece of information: - \"Does Claude really need this explanation?\" - \"Can I assume Claude knows this?\" - \"Does this paragraph justify its token cost?\" Good Example (50 tokens): python import pdfplumber with pdfplumber.open(\"file.pdf\") as pdf:     text = pdf.pages[0].extracttext() Bad Example (150 tokens): The concise version assumes Claude knows what PDFs are and how libraries work.  Set Appropriate Degrees of Freedom Match specificity to the task's fragility and variability. High freedom (text-based instructions): - Multiple approaches are valid - Decisions depend",
    "url": "/skills-bank/best-practices",
    "category": "skills-bank"
  },
  {
    "id": "skills-bank/overview",
    "title": "Skills Overview",
    "content": "Agent Skills Create, manage, and share Skills to extend Claude's capabilities in Claude Code.  What is a Skill? A Skill is a markdown file that teaches Claude how to do something specific: reviewing PRs using your team's standards, generating commit messages in your preferred format, or querying your company's database schema. When you ask Claude something that matches a Skill's purpose, Claude automatically applies it.  How Skills Work Skills are model-invoked: Claude decides which Skills to use based on your request. You don't need to explicitly call a Skill. Claude automatically applies relevant Skills when your request matches their description. When you send a request, Claude follows these steps: 1. Discovery: At startup, Claude loads only the name and description of each available Skill 2. Activation: When your request matches a Skill's description, Claude asks to use the Skill 3. Execution: Claude follows the Skill's instructions, loading referenced files or running bundled scri",
    "url": "/skills-bank/overview",
    "category": "skills-bank"
  },
  {
    "id": "skills-bank/template-skill",
    "title": "template-skill",
    "content": "SKILLTEMPLATE || VER: 1.0.2 > [!NOTE] > Use this template to define a skill with maximum operational clarity.  Metadata - Name: - Owner: - Domain: - Version: - Status: draft | active | deprecated - Last Updated:  Inputs - Required: - Optional: - Constraints:  Outputs - Primary: - Secondary: - Quality Gates:  Required Tools - Local: - External: - MCP:  Logic Flow 1.  2.  3.   Edge Cases -   Verification -  > [!TIP] > Keep logic flow executable. If a step can't be performed, delete it. > [!CAUTION] > Avoid cross-skill dependencies unless they are version-pinned.",
    "url": "/skills-bank/template-skill",
    "category": "skills-bank"
  },
  {
    "id": "tooling-mcp",
    "title": "Tooling and MCP",
    "content": "Tooling and MCP MCP server configurations and custom tool definitions for AI agents.  What is MCP? Model Context Protocol (MCP) provides a standardized way to connect AI agents to external tools, data sources, and services. It's an open source standard for AI-tool integrations.  Documentation  Claude Code MCP - MCP in Claude Code - Connecting Claude Code to tools via MCP - MCP Standard - Protocol reference and standards  What You Can Do with MCP With MCP servers connected, you can: - Issue Trackers: Implement features from JIRA, Linear, or GitHub Issues - Monitoring: Analyze data from Sentry, Statsig, or custom dashboards - Databases: Query PostgreSQL, MySQL, or other databases directly - Design Tools: Integrate designs from Figma or other design tools - Communication: Access Slack messages, Gmail drafts, and more - Automation: Chain multiple tools for complex workflows  Transport Types | Type | Use Case | Example | |------|----------|---------| | HTTP | Remote cloud services | Notion,",
    "url": "/tooling-mcp",
    "category": "tooling-mcp"
  },
  {
    "id": "tooling-mcp/claude-mcp",
    "title": "MCP in Claude Code",
    "content": "Connect Claude Code to Tools via MCP Claude Code can connect to hundreds of external tools and data sources through the Model Context Protocol (MCP), an open source standard for AI-tool integrations.  What You Can Do with MCP With MCP servers connected, you can ask Claude Code to: - Implement features from issue trackers: \"Add the feature described in JIRA issue ENG-4521 and create a PR on GitHub.\" - Analyze monitoring data: \"Check Sentry and Statsig to check the usage of the feature described in ENG-4521.\" - Query databases: \"Find emails of 10 random users who used feature ENG-4521, based on our PostgreSQL database.\" - Integrate designs: \"Update our standard email template based on the new Figma designs that were posted in Slack\" - Automate workflows: \"Create Gmail drafts inviting these 10 users to a feedback session about the new feature.\"  Installing MCP Servers  Option 1: Remote HTTP Server (Recommended) HTTP servers are the recommended option for connecting to remote MCP servers. ",
    "url": "/tooling-mcp/claude-mcp",
    "category": "tooling-mcp"
  },
  {
    "id": "tooling-mcp/mcp-standard",
    "title": "mcp-standard",
    "content": "MCPSTANDARD || VER: 1.0.2 > [!NOTE] > Purpose: Document and share MCP server configurations between two operators with zero ambiguity.  Required Sections - Server Identity: Name, owner, repo, contact. - Runtime: Node/Python version, OS target, start command. - Capabilities: Tools, resources, prompts exposed. - Auth: Tokens, scopes, rotation policy. - Network: Ports, endpoints, CORS rules. - Security: Sandboxing, file access, secrets storage. - Change Log: Version, date, breaking changes.  Share Protocol 1. Export server config and tool schema. 2. Redact secrets; replace with placeholders. 3. Provide a verified start command and health check. 4. Sync via repo PR or direct file drop in . > [!TIP] > Include one minimal usage example per tool. Keep outputs deterministic. > [!CAUTION] > Never paste real keys. Use  placeholders and describe where they live.",
    "url": "/tooling-mcp/mcp-standard",
    "category": "tooling-mcp"
  }
]